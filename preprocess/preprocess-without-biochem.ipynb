{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pickle\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IN_FILE = 'input/danExtractIn.txt'\n",
    "INPUT_OUT_FILE = 'input/danExtractOut.txt'\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_start_time = datetime.datetime.now()\n",
    "print('{} started at {}'.format(sys.argv[0], script_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "print('Reading data...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "in_df = pd.read_csv(INPUT_IN_FILE, index_col=['EntryDate'], parse_dates=['EntryDate'])\n",
    "out_df = pd.read_csv(INPUT_OUT_FILE, index_col=['EntryDate'], parse_dates=['EntryDate'])\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)\n",
    "\n",
    "# Replace all non-zero values with True\n",
    "in_df.CodeValue = True\n",
    "out_df.CodeValue = True\n",
    "\n",
    "# Remove biochemistry Read codes, making it more suitable for Apriori\n",
    "in_df = in_df.loc[~in_df.ReadCode.str.startswith('4')]\n",
    "out_df = out_df.loc[~out_df.ReadCode.str.startswith('4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the tables of the main DataFrames so that Read codes are on the x-axis and each row represents a patient record\n",
    "print('Pivoting table and filling missing values...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "in_pivot_df = in_df.pivot_table(index='PatID', columns='ReadCode', values='CodeValue')\n",
    "out_pivot_df = out_df.pivot_table(index='PatID', columns='ReadCode', values='CodeValue')\n",
    "\n",
    "# Add label column\n",
    "in_pivot_df['label'] = True\n",
    "out_pivot_df['label'] = False\n",
    "\n",
    "# Reset index and add autoincrementing ID column\n",
    "in_pivot_df.reset_index(inplace=True)\n",
    "out_pivot_df.reset_index(inplace=True)\n",
    "\n",
    "# Merge the in and out DataFrames\n",
    "merged_df = pd.concat([in_pivot_df, out_pivot_df])\n",
    "\n",
    "# Rename the index and add PatID to it\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "merged_df.index.names = ['ID']\n",
    "merged_df.set_index('PatID', append=True, inplace=True)\n",
    "\n",
    "# Shuffle the DataFrames\n",
    "merged_df = merged_df.sample(frac=1)\n",
    "\n",
    "# Replace NaN values with False\n",
    "merged_df.fillna(value=False, inplace=True)\n",
    "\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)\n",
    "\n",
    "# Print some stats\n",
    "print('DataFrame info:')\n",
    "merged_df.info()\n",
    "print('In DataFrame shape: {} rows, {} columns'.format(*in_pivot_df.shape))\n",
    "print('Out DataFrame shape: {} rows, {} columns'.format(*out_pivot_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all patients for train-test splitting\n",
    "print('Performing train-test splitting...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "# TODO: Once we've merged DataFrames there will be duplicate PatIDs, so do the train-test split before this happens\n",
    "all_pts = pd.unique(merged_df.index.get_level_values('PatID').values)\n",
    "\n",
    "# 80% split for training, 20% split for testing\n",
    "train_pts, test_pts = train_test_split(all_pts, test_size=TEST_SIZE)\n",
    "\n",
    "is_train_pt = merged_df.index.get_level_values('PatID').isin(train_pts)\n",
    "is_test_pt = merged_df.index.get_level_values('PatID').isin(test_pts)\n",
    "\n",
    "X_train = merged_df[is_train_pt]\n",
    "X_test = merged_df[is_test_pt]\n",
    "\n",
    "# Split features and labels\n",
    "y_train, y_test = X_train.pop('label'), X_test.pop('label')\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to output files\n",
    "X_train.to_pickle('X_train_without_biochem.pkl')\n",
    "X_test.to_pickle('X_test_without_biochem.pkl')\n",
    "\n",
    "y_train.to_pickle('y_train_without_biochem.pkl')\n",
    "y_test.to_pickle('y_test_without_biochem.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
