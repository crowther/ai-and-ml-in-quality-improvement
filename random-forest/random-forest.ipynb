{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import datetime\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_FILE = '../X_train.pkl'\n",
    "X_TEST_FILE = '../X_test.pkl'\n",
    "Y_TRAIN_FILE = '../y_train.pkl'\n",
    "Y_TEST_FILE = '../y_test.pkl'\n",
    "METRICS_FILE = 'metrics.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dan/.local/share/virtualenvs/machine-learning-for-quality-improvement-NjV9ptfu/lib/python3.6/site-packages/ipykernel_launcher.py started at 2018-06-06 23:27:15.917411\n"
     ]
    }
   ],
   "source": [
    "script_start_time = datetime.datetime.now()\n",
    "print('{} started at {}'.format(sys.argv[0], script_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rubric dictionary...\n",
      " done in 3.51s\n"
     ]
    }
   ],
   "source": [
    "# Generate the rubric dictionary\n",
    "print('Generating rubric dictionary...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "in_read_file = open('../input/large_anon_test_records_for_sharing.csv', mode='r')\n",
    "out_read_file = open('../input/large_anon_test_records_for_sharing.csv', mode='r')\n",
    "in_read_csv = csv.reader(in_read_file)\n",
    "out_read_csv = csv.reader(out_read_file)\n",
    "in_rubrics = {row[4]: row[3] for row in in_read_csv}\n",
    "out_rubrics = {row[4]: row[3] for row in out_read_csv}\n",
    "rubrics = {**in_rubrics, **out_rubrics}\n",
    "in_read_file.close()\n",
    "out_read_file.close()\n",
    "\n",
    "def get_rubric(read_code):    \n",
    "    return rubrics.get(read_code, 'unknown')\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data... done in 0.07s\n",
      "True     74\n",
      "False    74\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all patients for train-test splitting\n",
    "print('Reading data...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "X_train, X_test = pd.read_pickle(X_TRAIN_FILE), pd.read_pickle(X_TEST_FILE)\n",
    "y_train, y_test = pd.read_pickle(Y_TRAIN_FILE), pd.read_pickle(Y_TEST_FILE)\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search and training model...Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n",
      "[CV] max_depth=None, max_features=log2, min_samples_split=2, n_estimators=2048 \n"
     ]
    }
   ],
   "source": [
    "print('Performing grid search and training model...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048],\n",
    "#     'max_depth': [None],\n",
    "#     'min_samples_split': [2],\n",
    "#     'max_features': ['auto', 'log2', None]\n",
    "# }\n",
    "param_grid = {\n",
    "    'n_estimators': [2048],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'max_features': ['log2']\n",
    "}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, n_jobs=16, verbose=50, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)\n",
    "print('The best parameters are {} with a score of {}'.format(grid.best_params_, grid.best_score_))\n",
    "\n",
    "print('Making predictions...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "train_preds = grid.predict(X_train)\n",
    "test_preds = grid.predict(X_test)\n",
    "print(' done in {:.2f}s'.format(timeit.default_timer() - start_time), flush=True)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "print('Train accuracy: {:.2f} Test accuracy: {:.2f}'.format(train_accuracy * 100, test_accuracy * 100.0))\n",
    "\n",
    "classification_report = classification_report(y_test, test_preds)\n",
    "print('Classification report:\\n ', classification_report)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, test_preds)\n",
    "print('Confusion matrix:\\n ', confusion_matrix)\n",
    "\n",
    "with open(METRICS_FILE, mode='w') as file:\n",
    "    file.write('Train accuracy: {:.2f} Test accuracy: {:.2f}\\n'.format(train_accuracy * 100, test_accuracy * 100.0))\n",
    "    file.write('Classification report: {}\\n'.format(classification_report))\n",
    "    file.write('Confusion matrix: {}\\n'.format(confusion_matrix))\n",
    "    file.write('Cross validation results: {}\\n'.format(grid.cv_results_))\n",
    "print('Metrics saved at {}'.format(METRICS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Sorting importance...', end='')\n",
    "start_time = timeit.default_timer()\n",
    "forest = grid.best_estimator_\n",
    "feature_dict = {get_rubric(f): i for f, i in zip(X_test.columns, forest.feature_importances_)}\n",
    "\n",
    "importances = pd.DataFrame.from_dict(feature_dict, orient='index').rename(columns={0: 'importance'})\n",
    "\n",
    "importances.sort_values(by='importance', inplace=True, ascending=False)\n",
    "importances.to_csv('importances.csv')\n",
    "importances.to_pickle('importances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_end_time = datetime.datetime.now()\n",
    "print('{} completed at {}'.format(\n",
    "    sys.argv[0], \n",
    "    script_end_time)\n",
    ")\n",
    "print('Total time: {}'.format(script_end_time - script_start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
